window.BENCHMARK_DATA = {
  "lastUpdate": 1745609938783,
  "repoUrl": "https://github.com/LLNL/quandary",
  "entries": {
    "Benchmark": [
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "da5a77d076f0a812a8b5694c82f72cb16df314f7",
          "message": "Revert custom pytest hook and put benchmark format conversion in own file",
          "timestamp": "2025-04-24T22:48:06Z",
          "url": "https://github.com/LLNL/quandary/commit/da5a77d076f0a812a8b5694c82f72cb16df314f7"
        },
        "date": 1745535643724,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.0551612270530315,
            "unit": "seconds",
            "range": "0.10971771336277314",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2435194292338565,
            "unit": "seconds",
            "range": "0.009293463224632708",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 163.54
            }
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 163.54,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 163.54
            }
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "da5a77d076f0a812a8b5694c82f72cb16df314f7",
          "message": "Revert custom pytest hook and put benchmark format conversion in own file",
          "timestamp": "2025-04-24T22:48:06Z",
          "url": "https://github.com/LLNL/quandary/commit/da5a77d076f0a812a8b5694c82f72cb16df314f7"
        },
        "date": 1745539939245,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.296414813795127,
            "unit": "seconds",
            "range": "0.6155023926807012",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2689366455888376,
            "unit": "seconds",
            "range": "0.04634240184557715",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 164.23
            }
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 164.23,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 164.23
            }
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "865246ee08d5410cd395bcd31f4f40f324b96306",
          "message": "Update the GitLab ref and later only submit results from main to dashboard",
          "timestamp": "2025-04-25T16:08:05Z",
          "url": "https://github.com/LLNL/quandary/commit/865246ee08d5410cd395bcd31f4f40f324b96306"
        },
        "date": 1745597817866,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.3894706276711077,
            "unit": "seconds",
            "range": "0.7198294542390121"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2576955430675298,
            "unit": "seconds",
            "range": "0.0404835808625153"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 163.95,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "687aae72c853d91796866bc60bd59251711b15be",
          "message": "Add a step to make sure workflow passes/fails in PR associated with branch",
          "timestamp": "2025-04-25T16:42:32Z",
          "url": "https://github.com/LLNL/quandary/commit/687aae72c853d91796866bc60bd59251711b15be"
        },
        "date": 1745599698045,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.3686082514002917,
            "unit": "seconds",
            "range": "0.7101005442028753"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2346843560226262,
            "unit": "seconds",
            "range": "0.0057468293343989575"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 164.19,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "00b55d3394485b399c85319e45fb5f0c23fe2e3c",
          "message": "WIP test memory increase",
          "timestamp": "2025-04-25T16:45:27Z",
          "url": "https://github.com/LLNL/quandary/commit/00b55d3394485b399c85319e45fb5f0c23fe2e3c"
        },
        "date": 1745601314319,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.484969047480263,
            "unit": "seconds",
            "range": "0.7593723631806658"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 58.75,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2651573360199109,
            "unit": "seconds",
            "range": "0.005363640519952414"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 245.65,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "31f24457c5626bcd5dbac791abb133dee31a748f",
          "message": "Fix benchmark workflow to report results on PR",
          "timestamp": "2025-04-25T17:20:23Z",
          "url": "https://github.com/LLNL/quandary/commit/31f24457c5626bcd5dbac791abb133dee31a748f"
        },
        "date": 1745602067362,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.4359597209841013,
            "unit": "seconds",
            "range": "0.6366594742505425"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 58.75,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.9082177517702803,
            "unit": "seconds",
            "range": "0.7691083674711411"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 245.36,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "db6b4e89a1c24a43d460a8b37103a85292bfe054",
          "message": "WIP test slow execution time",
          "timestamp": "2025-04-25T17:21:26Z",
          "url": "https://github.com/LLNL/quandary/commit/db6b4e89a1c24a43d460a8b37103a85292bfe054"
        },
        "date": 1745602723917,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 4.1569153787335384,
            "unit": "seconds",
            "range": "0.22142688726527357"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 2.253983880323358,
            "unit": "seconds",
            "range": "0.006758338542511889"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 163.96,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "d20d1b7f500a0f9f9de1cd44ee6267c42f7fad34",
          "message": "Add perfomance test case",
          "timestamp": "2025-04-25T19:16:30Z",
          "url": "https://github.com/LLNL/quandary/commit/d20d1b7f500a0f9f9de1cd44ee6267c42f7fad34"
        },
        "date": 1745609938378,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[nlevels_32_32_32_32_32] - Time",
            "value": 50.23541713322047,
            "unit": "seconds",
            "range": "0.8941366109498384"
          },
          {
            "name": "test_eval[nlevels_32_32_32_32_32] - Memory",
            "value": 5044.14,
            "unit": "MB"
          }
        ]
      }
    ]
  }
}