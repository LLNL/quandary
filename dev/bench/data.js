window.BENCHMARK_DATA = {
  "lastUpdate": 1745599699065,
  "repoUrl": "https://github.com/LLNL/quandary",
  "entries": {
    "Benchmark": [
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "da5a77d076f0a812a8b5694c82f72cb16df314f7",
          "message": "Revert custom pytest hook and put benchmark format conversion in own file",
          "timestamp": "2025-04-24T22:48:06Z",
          "url": "https://github.com/LLNL/quandary/commit/da5a77d076f0a812a8b5694c82f72cb16df314f7"
        },
        "date": 1745535643724,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.0551612270530315,
            "unit": "seconds",
            "range": "0.10971771336277314",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2435194292338565,
            "unit": "seconds",
            "range": "0.009293463224632708",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 163.54
            }
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 163.54,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 163.54
            }
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "da5a77d076f0a812a8b5694c82f72cb16df314f7",
          "message": "Revert custom pytest hook and put benchmark format conversion in own file",
          "timestamp": "2025-04-24T22:48:06Z",
          "url": "https://github.com/LLNL/quandary/commit/da5a77d076f0a812a8b5694c82f72cb16df314f7"
        },
        "date": 1745539939245,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.296414813795127,
            "unit": "seconds",
            "range": "0.6155023926807012",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 1,
              "memory_mb": 39.16
            }
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2689366455888376,
            "unit": "seconds",
            "range": "0.04634240184557715",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 164.23
            }
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 164.23,
            "unit": "MB",
            "range": "0",
            "extra": {
              "number_of_processors": 4,
              "memory_mb": 164.23
            }
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "865246ee08d5410cd395bcd31f4f40f324b96306",
          "message": "Update the GitLab ref and later only submit results from main to dashboard",
          "timestamp": "2025-04-25T16:08:05Z",
          "url": "https://github.com/LLNL/quandary/commit/865246ee08d5410cd395bcd31f4f40f324b96306"
        },
        "date": 1745597817866,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.3894706276711077,
            "unit": "seconds",
            "range": "0.7198294542390121"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2576955430675298,
            "unit": "seconds",
            "range": "0.0404835808625153"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 163.95,
            "unit": "MB"
          }
        ]
      },
      {
        "commit": {
          "author": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "committer": {
            "name": "Tara Drwenski",
            "username": "tdrwenski",
            "email": "drwenski1@llnl.gov"
          },
          "id": "687aae72c853d91796866bc60bd59251711b15be",
          "message": "Add a step to make sure workflow passes/fails in PR associated with branch",
          "timestamp": "2025-04-25T16:42:32Z",
          "url": "https://github.com/LLNL/quandary/commit/687aae72c853d91796866bc60bd59251711b15be"
        },
        "date": 1745599698045,
        "tool": "customSmallerIsBetter",
        "benches": [
          {
            "name": "test_eval[config_template_1] - Time",
            "value": 3.3686082514002917,
            "unit": "seconds",
            "range": "0.7101005442028753"
          },
          {
            "name": "test_eval[config_template_1] - Memory",
            "value": 39.16,
            "unit": "MB"
          },
          {
            "name": "test_eval[config_template_4] - Time",
            "value": 1.2346843560226262,
            "unit": "seconds",
            "range": "0.0057468293343989575"
          },
          {
            "name": "test_eval[config_template_4] - Memory",
            "value": 164.19,
            "unit": "MB"
          }
        ]
      }
    ]
  }
}